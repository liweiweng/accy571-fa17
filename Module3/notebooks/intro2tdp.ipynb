{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Text Data Processing\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explore how to actually pull text data of interest out of unstructured data sets. First we will review basic Python tools that can be used for either an initial data exploration or in many cases, more advanced data processing tasks. Next, we review another important tool, regular expressions, which can simplify the task of finding and selecting specific data in a large document. Python provides a native implementation of [regular expressions][re] through the `re` module.\n",
    "\n",
    "-----\n",
    "[re]: https://docs.python.org/3/library/re.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "[Text Data Processing](#Text-Data-Processing)\n",
    "\n",
    "- [Sequence Operators](#Sequence-Operators)\n",
    "\n",
    "- [String Functions](#String-Functions)\n",
    "\n",
    "- [Data Collection Classes](#Data-Collection-Classes)\n",
    "\n",
    "[Regular Expressions](#Regular-Expressions)\n",
    "\n",
    "-----\n",
    "\n",
    "Before proceeding with the rest of this notebook, we first define our _data_ directory and load a sample text document, in this case an email.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we find our HOME directory\n",
    "home_dir = !echo $HOME\n",
    "\n",
    "# Define data directory\n",
    "data_dir = home_dir[0] +'/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/data_scientist/data/\n"
     ]
    }
   ],
   "source": [
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/data_scientist/data/email.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1d7ac887927a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read in sample email document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'email.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/data_scientist/data/email.txt'"
     ]
    }
   ],
   "source": [
    "# Read in sample email document\n",
    "with open (data_dir + 'email.txt', 'r') as myfile:\n",
    "    msg = myfile.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Text Data Processing\n",
    "\n",
    "In many cases, we will be presented with unstructured or even semi-structured text data. For example, Tweet messages, email messages, or other documents can often be considered as character sequences. In these cases, we often can perform basic data processing by employing built-in Python data structures and collections. \n",
    "\n",
    "The main tool we can use for text processing is the Python `string` object and its associated methods. One important point to remember is that in Python, a `string` is immutable, thus any change will create a new `string`. This will have an impact on using Python to process large text data sets, which often leads to other solutions, of which several are presented later in this notebook. \n",
    "\n",
    "In the following two Code cells, we first display the message's data type, which is class string. After which, we display the message itself, which, since the message is a sequence of characters, will wrap as the size of the browser window is changed.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message is encoded as type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Message data type\n",
    "print(f'Message is encoded as type: {type(msg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: ACCY 570 Instructor <no-reply@illinois.edu>\n",
      "Subject: [Instr Note] New Docker Course Image\n",
      "Date: September 29, 2017 at 5:54:37 PM CDT\n",
      "To: a.student@gmail.com\n",
      "\n",
      "Instructor Robert J. Brunner posted a new Note. \n",
      "\n",
      "New Docker Course Image\n",
      "\n",
      "We generated a new Docker course image. If you want to follow along on your laptop or work on the course Notebooks offline, you should download this new image by issuing a \n",
      "\n",
      "docker pull lcdm/rppdm-standalone\n",
      "\n",
      "command at a Unix command line prompt. On the other hand, if you simply use the JupyterHub Server, no action is required on your part (we have already updated the server).\n",
      "\n",
      "Let us know if you have any questions.\n",
      "\n",
      "Robert\n",
      "\n",
      "You're receiving this email because a.student@gmail.com is enrolled in ACCY 570 at University of Illinois. Sign in to manage your email preferences or un-enroll from this class. \n"
     ]
    }
   ],
   "source": [
    "# Display message\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Sequence Operators\n",
    "\n",
    "Since a Python _string_ is a standard data structure, the standard [Python sequence operators][pso] can be used to quickly perform basic text data processing.  Given a value `v`, integer `n`, and similar typed sequences `s` and `t`:\n",
    "\n",
    "| Operation | Description |\n",
    "| ----- | ----- |\n",
    "| `v in s`| `True` if `v` is in the sequence `s`, otherwise `False`|\n",
    "| `v not in s`| `False` if `v` is in the sequence `s`, otherwise `True`|\n",
    "| `s + t`| concatenation of `s` and `t`|\n",
    "| `s * n` or `n* s`| `n` shallow copies of `s` concatenated|\n",
    "| `len(s)`| the number of elements in the sequence `s`|\n",
    "| `min(s)`| the smallest elements in the sequence `s`|\n",
    "| `max(s)`| the largest of elements in the sequence `s`|\n",
    "| `s.count(v)`| number of times `v` appears in `s`|\n",
    "\n",
    "In the following Code cells, we demonstrate the use of most of these operators on our email message. First, we count and display the number of characters in the message via the `len` function. Next, we test if a character sequence `Brunner` is in the message, which returns `True`. Third, we count and display the number of times a sequence of characters (`ou`) appears in the message.\n",
    "\n",
    "Finally, we find and display the maximum and minimum characters in the message. Note, the value of a character derives from its [Unicode][pu] numerical value. One other thing the second Code cell demonstrates is the conversion of the value `max(msg)` via the special format code `!r`. This converts the result into its native representation, which is Unicode string, which allows the Unicode to be displayed instead of processed directly (we would not see the result otherwise).\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "[pso]: https://docs.python.org/3/library/stdtypes.html#common-sequence-operations\n",
    "[pu]: https://docs.python.org/3/howto/unicode.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847 characters in email.\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(msg)} characters in email.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print('Brunner' in msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ou\" appears 13 times in the message.\n"
     ]
    }
   ],
   "source": [
    "print(f'\"ou\" appears {msg.count(\"ou\")} times in the message.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Max : Min) characters = ('\\xa0' : '\\n')\n"
     ]
    }
   ],
   "source": [
    "print(f'(Max : Min) characters = ({max(msg)!r} : {min(msg)!r})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### String Functions\n",
    "\n",
    "The `string` object also has a number of built-in, [useful methods][pystm]:\n",
    "\n",
    "- `split`: Return a list of token strings that are delimited by a character, such as space.\n",
    "\n",
    "- `find`: return the lowest index in the string where a substring is located.\n",
    "\n",
    "- `replace`: return a new string with all occurrences of a pattern replaced.\n",
    "\n",
    "- `join`: return a string that is the combination of the input strings\n",
    "\n",
    "- `count`: return the number of non-overlapping instances of a substring.\n",
    "\n",
    "- `lower`: convert text to lowercase characters.\n",
    "\n",
    "- `lstrip` / `rstrip`: return a string with the leading/trailing characters removed.\n",
    "\n",
    "These functions are demonstrated int he following Code cells, where we apply them to the email message to replace text, split the message into tokens, join tokens by using a character sequence, change the case of a token, strip characters from tokens, and find a specific character sequence.\n",
    "\n",
    "-----\n",
    "\n",
    "[pystm]: https://docs.python.org/3/library/stdtypes.html#string-methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: ACCY 570 Instructor <no-reply@illinois.edu> Subject: [Instr Note] New Docker Course Image Date: September 29, 2017 at 5:54:37 PM CDT To: a.student@gmail.com  Instructor Robert J. Brunner posted a new Note.   New Docker Course Image  We generated a new Docker course image. If you want to follow along on your laptop or work on the course Notebooks offline, you should download this new image by issuing a   docker pull lcdm/rppdm-standalone  command at a Unix command line prompt. On the other hand, if you simply use the JupyterHub Server, no action is required on your part (we have already updated the server).  Let us know if you have any questions.  Robert  You're receiving this email because a.student@gmail.com is enrolled in ACCY 570 at University of Illinois. Sign in to manage your email preferences or un-enroll from this class. \n"
     ]
    }
   ],
   "source": [
    "# Replace text, in this case newline with space  \n",
    "msg_text = msg.replace('\\n', ' ')\n",
    "print(msg_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  'to',\n",
      "   'manage',\n",
      "   'your',\n",
      "   'email',\n",
      "   'preferences',\n",
      "   'or',\n",
      "   'un-enroll',\n",
      "   'from',\n",
      "   'this',\n",
      "   'class.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize message\n",
    "words = msg.split()\n",
    "\n",
    "# Pretty print last ten tokens\n",
    "import pprint as pp\n",
    "pp.pprint(words[-10:], indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to*-*manage*-*your*-*email*-*preferences*-*or*-*un-enroll*-*from*-*this*-*class.\n"
     ]
    }
   ],
   "source": [
    "# Join last ten tokens with *-* character sequence\n",
    "print('*-*'.join(words[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class.\n",
      "CLASS.\n"
     ]
    }
   ],
   "source": [
    "# Extract last word and change to uppercase\n",
    "print(words[-1])\n",
    "print(words[-1].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to to\n",
      "manage manage\n",
      "your ur\n",
      "email email\n",
      "preferences preferences\n",
      "or r\n",
      "un-enroll un-enroll\n",
      "from from\n",
      "this this\n",
      "class. class.\n"
     ]
    }
   ],
   "source": [
    "# Strip 'yo' from last ten tokens\n",
    "# Display token and stripped token\n",
    "for word in words[-10:]:\n",
    "    print(word, word.lstrip('yo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find string sequence\n",
    "msg_text.find('ACCY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACCY'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract sequence\n",
    "msg[6:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accy'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert sequence to lowercase\n",
    "msg[6:10].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Since `words` is a list of tokens, we can employ standard Python `list` methods. For example, we can sort the list of tokens, either in ascending order (the default), or descending order. Both approaches are shown in the following two Code cells, where we sort in both orders and display the last ten tokens.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use', 'want', 'work', 'you', 'you', 'you', 'you', 'your', 'your', 'your']\n"
     ]
    }
   ],
   "source": [
    "# Sort tokens and display last ten\n",
    "words.sort()\n",
    "pp.pprint(words[-10:], indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  'Brunner',\n",
      "   'ACCY',\n",
      "   'ACCY',\n",
      "   '<no-reply@illinois.edu>',\n",
      "   '5:54:37',\n",
      "   '570',\n",
      "   '570',\n",
      "   '29,',\n",
      "   '2017',\n",
      "   '(we']\n"
     ]
    }
   ],
   "source": [
    "# Reverse sort tokens and display last ten\n",
    "words.sort(reverse=True)\n",
    "pp.pprint(words[-10:], indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Data Collection Classes\n",
    "\n",
    "Python provides additional [data collection classes][cl] in the `collections` library, which is part of the standard Python distribution. Current;y, this library introduces the `namedTuple`, `deque`, `ChainMap`, `Counter`, `OrderedDict`, `defaultDict`, `UserDict`, `UserList`, and `UserString` classes. In the following code example, we demonstrate the use of a `Counter` object to perform a simple word count.\n",
    "\n",
    "-----\n",
    "[cl]: https://docs.python.org/3/library/collections.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('you', 4),\n",
      " ('the', 4),\n",
      " ('a', 4),\n",
      " ('your', 3),\n",
      " ('this', 3),\n",
      " ('on', 3),\n",
      " ('new', 3),\n",
      " ('at', 3),\n",
      " ('Docker', 3),\n",
      " ('to', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Count tokens by using a collection\n",
    "import collections as cl\n",
    "\n",
    "# Find and display ten most common tokens \n",
    "mr = cl.Counter(words)\n",
    "pp.pprint(mr.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Regular Expressions\n",
    "\n",
    "Regular expressions, or RE or regexes, are expressions that can be used to match one or more occurrences of a particular pattern. Regular expressions are not unique to Python, they are used in many programming languages and many Unix command line tools like sed, grep, or awk. [Regular expressions][re] are used in Python through the `re` module. To build a regular expression, you need to understand the syntax of the RE language. Once a regular expression is developed, it is compiled and executed by an engine written in C in order to provide fast execution.\n",
    "\n",
    "To begin, most characters in a regular expression simply match themselves, For example `python` would match any occurrence of the six letters `python` either alone or embedded in another word. There are several special characters, known as metacharacters, that control the behavior of the rest of the regular expression. These metacharacters are listed in the following table.\n",
    "\n",
    "| Metacharacter | Meaning | Example |\n",
    "| ---- | ----- | ----- |\n",
    "| . |  Matches any character except a newline | `1.3` matches `123`, `1a3`, and `1#3` among others |\n",
    "| ^ | Matches sequence at the beginning of the line| `^Python` matches `Python` at the beginning of a line |\n",
    "| $ | Matches sequence at the end of the line | `Python$` matches `Python` at the end of a line |\n",
    "| * | Matches zero or more occurrences of a pattern | `12*3` matches `13`, `123`, `1223`, etc. |\n",
    "| + |  Matches one or more occurrences of a pattern | `12+3` matches `123`, `1223`, etc. |\n",
    "| ? |  Matches zero or one occurrences of a pattern | `12?3` matches `13` and `123` |\n",
    "| { }| Match repeated qualifier | `{m, n}` means match at least `m` and at most `n` occurrences | \n",
    "| [ ] | Used to specify a character class | `[a-z]` means match any lower case character |\n",
    "| \\ | Escape character | `\\w` means match an alphanumeric character, `\\d` means match numerical character, `\\s` means match any whitespace character, and `\\\\` means match a backslash |\n",
    "| &#124; | or operator | `A ` &#124; ` B` match either `A` or `B` |\n",
    "| ( ) | Grouping Operator | (a, b) |\n",
    "\n",
    "One additional point to remember is that inside a character class (i.e., `[ ]`) many of these metacharacters lose their special meaning, and thus can be used to match themselves. For example, inside a character class, the `^` character means _not_, so `[^\\w]` means match any non-alphanumeric character.\n",
    "\n",
    "To master regular expressions requires a lot of practice, but the investment is well worth it as they are used in many different contexts and can greatly simplify otherwise complex tasks. Given a regular expression, there are several functions that can be used to process text data.\n",
    "\n",
    "- `compile`: compiles a regular expression for faster evaluation.\n",
    "- `search`: find regular expression in string\n",
    "- `match`: find regular expression at start of string\n",
    "- `split`: splits the string by matches of a regular expression.\n",
    "- `sub`: replaces substrings that match a regular expression with different string\n",
    "\n",
    "In the following Code cells, we repeat several of our previous string processing examples, by using regular expressions to find text sequences, transform text sequences, and to find most common tokens (note the result is slightly different to the order in which the regular expression finds matches).\n",
    "\n",
    "-----\n",
    "[re]: https://docs.python.org/3/howto/regex.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006-010: ACCY\n",
      "740-744: ACCY\n"
     ]
    }
   ],
   "source": [
    "# Find and iterate over instances of ACCY,\n",
    "# extract starting and ending indices\n",
    "# and entire matching token\n",
    "\n",
    "import re\n",
    "for match in re.finditer(r'ACCY', msg):\n",
    "    print(f'{match.start():03d}-{match.end():03d}: {match.group(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303-305: on\n",
      "307-309: on\n",
      "330-332: on\n",
      "443-445: on\n",
      "487-489: On\n",
      "554-556: on\n",
      "569-571: on\n",
      "655-657: on\n"
     ]
    }
   ],
   "source": [
    "# Find and iterate over instances of either on, On, or ON,\n",
    "# extract starting and ending indices\n",
    "# and entire matching token\n",
    "\n",
    "for match in re.finditer(r'on|On|ON', msg):\n",
    "    print(f'{match.start():03d}-{match.end():03d}: {match.group(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "011-014: 570\n",
      "112-114: 29\n",
      "116-120: 2017\n",
      "124-125: 5\n",
      "126-128: 54\n",
      "129-131: 37\n",
      "745-748: 570\n"
     ]
    }
   ],
   "source": [
    "# Find and iterate over instances of one or more \n",
    "# numerical values, extract starting and ending indices\n",
    "# and entire matching token\n",
    "\n",
    "for match in re.finditer(r'\\d+', msg):\n",
    "    print(f'{match.start():03d}-{match.end():03d}: {match.group(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: ACCY 570 ******ctor <no-reply@******is.edu>\\n******t: [Instr Note] New ****** ****** Image\\nDate: ******ber 29, 2017 at 5:54:37 PM CDT\\nTo: a.******t@gmail.com\\n\\n******ctor ****** J. ******r ****** a new Note. \\n\\nNew ****** ****** Image\\n\\nWe ******ted a new ****** ****** image. If you want to ****** along on your ****** or work on the ****** ******oks ******e, you ****** ******ad this new image by ******g a\\xa0\\n\\n****** pull lcdm/rppdm-******lone\\n\\n******d at a Unix ******d line ******. On the other hand, if you ****** use the ******rHub ******, no ****** is ******ed on your part (we have ******y ******d the ******).\\n\\nLet us know if you have any ******ons.\\n\\n******\\n\\nYou're ******ing this email ******e a.******t@gmail.com is ******ed in ACCY 570 at ******sity of ******is. Sign in to ****** your email ******ences or un-****** from this class. \""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace any six alpha character sequence with\n",
    "# six asterisk characters\n",
    "re.sub(r'[a-zA-Z]{6}', '******', msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 6),\n",
      " ('you', 4),\n",
      " ('the', 4),\n",
      " ('Docker', 3),\n",
      " ('at', 3),\n",
      " ('new', 3),\n",
      " ('on', 3),\n",
      " ('your', 3),\n",
      " ('this', 3),\n",
      " ('ACCY', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Define word boundary as Not any alphanumeric character \n",
    "# followed by a whitespace character. We repalce these boundaries\n",
    "# with a single space, and split on the space.\n",
    "pattern = re.compile(r'[^\\w\\s]')\n",
    "words = re.sub(pattern, ' ', msg).split()\n",
    "\n",
    "# Find and display top ten tokens\n",
    "mr = cl.Counter(words)\n",
    "pp.pprint(mr.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "Earlier in this notebook, we used the text data processing techniques to  manipulate unstructured text data. Now that you have run the cells in this notebook, go back to the relevant cells and make these changes. Be sure to understand how your changes impact the file input and output process.\n",
    "\n",
    "1. Modify the string tokenization code to convert all text to lowercase characters before accumulating the word counts.\n",
    "\n",
    "2. Use the Python set to obtain the list of unique words in the text message.\n",
    "\n",
    "3. Use Regular Expressions to extract the email header information (i.e., sender, receiver, date) from the email message text.\n",
    "\n",
    "As a challenge problem:\n",
    "\n",
    "1. Save several emails from within your mail reader and modify the Python code to process them in bulk to extract out the sender, date sent, and subject.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ancillary Information\n",
    "\n",
    "The following links are to additional documentation that you might find helpful in learning this material. Reading these web-accessible documents is completely optional.\n",
    "\n",
    "1. [Dive Into Python3][1] regular expression chapter.\n",
    "4. The [Python Collections][pycol] documentation.\n",
    "\n",
    "-----\n",
    "\n",
    "[1]: http://www.diveintopython3.net/regular-expressions.html\n",
    "[pycol]: https://docs.python.org/3/library/collections.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**&copy; 2017: Robert J. Brunner at the University of Illinois.**\n",
    "\n",
    "This notebook is released under the [Creative Commons license CC BY-NC-SA 4.0][ll]. Any reproduction, adaptation, distribution, dissemination or making available of this notebook for commercial use is not allowed unless authorized in writing by the copyright holder.\n",
    "\n",
    "[ll]: https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
