{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Recommender Systems\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook, we introduce the concept of a [Recommender System][rs]. Recommender systems are among the most popular machine learning techniques, and, in general, encompass a number of different types of machine learning algorithms that we have covered including classification, regression, and clustering. Some of the most popular recommender system approaches, however, are different and are fundamentally tied to data management. The classic example of a recommender system, is the market basket analysis, where data mining is performed on purchase transaction logs to first learn what types of objects are bought together (e.g., peanut butter and jelly) in order to, second, predict what someone might be interested in buying once they have selected an item (e.g., when peanut butter has been added to the cart, recommend jelly).\n",
    "\n",
    "More formally, the data structures that support this type  of analysis are known as frequent sets, since we collect sets of frequently purchased items. The most famous algorithm in this category is the [_a priori_][wap] algorithm, where we use what we have learned from previous transactions to make predictions before (i.e., _a priori_ information) someone completes a transaction. More generally, these algorithms are known as _collaborative filtering_, since the algorithm collaboratively filters through records of many individuals to identify trends. Formally, these types of algorithms are used to make recommendations, hence the name _recommender systems_. In addition to the traditional _market basket_ analysis, these algorithms are also used to make recommendations for video, such as Netflix or Hulu, and audio sites, such as Pandora or Spotify.\n",
    "\n",
    "In fact, anyone who has shopped online has been exposed to these algorithms. For example, at Amazon, when you are viewing the page for a particular item, you also are presented information on _other items you might be interested in_ and on _what other items people buy instead_. The first case is an example of item-based collaborative filtering, where the results of other items people have purchased together with this item are identified. The second is an example of user-based collaborative filtering, where the results from other, similar users, are used to identify items that might be of interest. Sometimes, however, the [results of this analysis can be problematic][tpg], and one should always be considerate of the impact predictions might have on the end user (this is clearly an area where _big brother_ impacts everyone).\n",
    "\n",
    "In this notebook, we explore a sample data set, movie reviews, that can be used to learn more about recommender systems. Since Python does not (yet) have a standard implementation of recommender systems, we instead develop a single, user-based collaborative filtering example that uses the movie review data to make recommendations for new movies.\n",
    "\n",
    "-----\n",
    "[rs]: https://en.wikipedia.org/wiki/Recommender_system\n",
    "[wap]: https://en.wikipedia.org/wiki/Apriori_algorithm\n",
    "[tpg]: http://www.workplaceethicsadvice.com/2012/02/target-sends-coupons-to-pregnant-girl-and-unawares-dad-explode.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[Movie Lens Data](#Movie-Lens-Data)\n",
    "\n",
    "[Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "\n",
    "[User Based Collaborative Filtering](#User-Based-Collaborative-Filtering)\n",
    "\n",
    "- [Cosine Similarity](#Cosine-Similarity)\n",
    "\n",
    "- [Single User Recommendation](#Single-User-Recommendation)\n",
    "\n",
    "- [Multiple User Recommendation](#Multiple-User-Recommendation)\n",
    "-----\n",
    "\n",
    "Before proceeding with the _Formalism_ section of this Notebook, we first have our standard notebook setup code.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Notebook\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "\n",
    "# We do this to ignore several specific Pandas warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Movie Lens Data\n",
    "\n",
    "To begin exploring recommender systems, we will explore the [Movie Lens][ml] data. One problem with recommender systems is that they can use significant resources to make predictions since a large quantity of data is required to make the best predictions. Originally, these algorithms were developed to work with relational database systems, working directly within the database engine for maximal performance. As a result, in this Notebook, we will restrict our analysis to the small Movie Lens data set.\n",
    "\n",
    "We can grab the latest version of the small Movie Lens data set and use within this notebook. Note, to grab the data for yourself, you can execute the following Unix commands, either in a code cell or at the Unix command prompt.\n",
    "\n",
    "```bash\n",
    "\n",
    "wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "\n",
    "unzip ml-latest-small.zip\n",
    "```\n",
    "\n",
    "The next few Code cells define our local data directory, and if the movie data does not exist, we download the data and _unzip_ it for later use.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we find our HOME directory\n",
    "home_dir = !echo $HOME\n",
    "\n",
    "# Define data directory\n",
    "data_dir = home_dir[0] +'/data/'\n",
    "ml_data_dir = data_dir + 'ml-latest-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /home/data_scientist/data/ml-latest-small.zip\n",
      "   creating: ml-latest-small/\n",
      "  inflating: ml-latest-small/links.csv  \n",
      "  inflating: ml-latest-small/movies.csv  \n",
      "  inflating: ml-latest-small/ratings.csv  \n",
      "  inflating: ml-latest-small/README.txt  \n",
      "  inflating: ml-latest-small/tags.csv  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2017-10-22 18:55:43--  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.34.235\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.34.235|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 918269 (897K) [application/zip]\n",
      "Saving to: ‘/home/data_scientist/data/ml-latest-small.zip’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  5%  451K 2s\n",
      "    50K .......... .......... .......... .......... .......... 11% 26.4M 1s\n",
      "   100K .......... .......... .......... .......... .......... 16%  785K 1s\n",
      "   150K .......... .......... .......... .......... .......... 22% 1.93M 1s\n",
      "   200K .......... .......... .......... .......... .......... 27% 1.37M 1s\n",
      "   250K .......... .......... .......... .......... .......... 33% 1.69M 1s\n",
      "   300K .......... .......... .......... .......... .......... 39% 1.36M 0s\n",
      "   350K .......... .......... .......... .......... .......... 44%  660K 0s\n",
      "   400K .......... .......... .......... .......... .......... 50%  626K 0s\n",
      "   450K .......... .......... .......... .......... .......... 55% 1.58M 0s\n",
      "   500K .......... .......... .......... .......... .......... 61%  842K 0s\n",
      "   550K .......... .......... .......... .......... .......... 66% 1.14M 0s\n",
      "   600K .......... .......... .......... .......... .......... 72% 1.67M 0s\n",
      "   650K .......... .......... .......... .......... .......... 78% 1.88M 0s\n",
      "   700K .......... .......... .......... .......... .......... 83% 1.62M 0s\n",
      "   750K .......... .......... .......... .......... .......... 89% 1.67M 0s\n",
      "   800K .......... .......... .......... .......... .......... 94% 1.37M 0s\n",
      "   850K .......... .......... .......... .......... ......    100% 1.53M=0.8s\n",
      "\n",
      "2017-10-22 18:55:44 (1.14 MB/s) - ‘/home/data_scientist/data/ml-latest-small.zip’ saved [918269/918269]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$data_dir\"\n",
    "\n",
    "# Note, we passed in a Python variable above to the Bash script \n",
    "# which is then accessed via positional parameter, or $1 in this case.\n",
    "\n",
    "# First test if file of interest does not exist\n",
    "if [ ! -f \"$1\" ] ; then\n",
    "\n",
    "# If it does not exist, we grab the file from the Internet and\n",
    "# store it locally in the data directory\n",
    "\n",
    "wget -O \"$1\"ml-latest-small.zip http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "\n",
    "cd \"$1\"\n",
    "unzip \"$1\"ml-latest-small.zip\n",
    "\n",
    "else\n",
    "    \n",
    "    echo \"Files already exists locally.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "This data set includes a summary document in a file called `README.txt`. This document contains a summary of this data, which is included verbatim below. You can read the entire file either at the command line or via `%load ml-latest-small/README.txt` in a code cell.\n",
    "\n",
    "> Summary\n",
    "> =======\n",
    "\n",
    "> This dataset (ml-latest-small) describes 5-star rating and free-text\n",
    "> tagging activity from [MovieLens](http://movielens.org), a movie\n",
    "> recommendation service. It contains 105339 ratings and 6138 tag\n",
    "> applications across 10329 movies. These data were created by 668 users\n",
    "> between April 03, 1996 and January 09, 2016. This dataset was generated\n",
    "> on January 11, 2016.\n",
    "\n",
    "> Users were selected at random for inclusion. All selected users had\n",
    "> rated at least 20 movies. No demographic information is included. Each\n",
    "> user is represented by an id, and no other information is provided.\n",
    "\n",
    "> The data are contained in four files, `links.csv`, `movies.csv`,\n",
    "> `ratings.csv` and `tags.csv`. More details about the contents and use of\n",
    "> all these files follows.\n",
    "\n",
    "> This is a *development* dataset. As such, it may change over time and is\n",
    "> not an appropriate dataset for shared research results. See available\n",
    "> *benchmark* datasets if that is your intent.\n",
    "\n",
    "> This and other GroupLens data sets are publicly available for download\n",
    "> at <http://grouplens.org/datasets/>.\n",
    "\n",
    "-----\n",
    "\n",
    "In the following code cells, we use Unix commands to display the contents of the small Movie Lens data and the number of ratings included.\n",
    "\n",
    "-----\n",
    "[ml]: http://grouplens.org/datasets/movielens/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3076\r\n",
      "drwxr-xr-x 2 data_scientist users    4096 Oct 17  2016 .\r\n",
      "drwxr-xr-x 4 data_scientist users    4096 Oct 22 18:55 ..\r\n",
      "-rw-r--r-- 1 data_scientist users  183372 Oct 17  2016 links.csv\r\n",
      "-rw-r--r-- 1 data_scientist users  458390 Oct 17  2016 movies.csv\r\n",
      "-rw-r--r-- 1 data_scientist users 2438266 Oct 17  2016 ratings.csv\r\n",
      "-rw-r--r-- 1 data_scientist users    8364 Oct 17  2016 README.txt\r\n",
      "-rw-r--r-- 1 data_scientist users   41902 Oct 17  2016 tags.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Show contents of small movie data set\n",
    "!ls -la $ml_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100005 /home/data_scientist/data/ml-latest-small/ratings.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Count number of lines in ratings\n",
    "!wc -l $ml_data_dir/ratings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "Before developing our recommendation system, we first explore the Movie Lens data. To simplify this task, we will read the ratings data and the movies data into two separate DataFrames. We then display several rows from each DataFrame, as well as compute and display some basic statistics.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define full file paths to files\n",
    "ratings_file = os.path.join(ml_data_dir, 'ratings.csv')\n",
    "movies_file = os.path.join(ml_data_dir, 'movies.csv')\n",
    "\n",
    "# Read data into DataFrames\n",
    "ratings = pd.read_csv(ratings_file)\n",
    "movies = pd.read_csv(movies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>2475</td>\n",
       "      <td>52 Pick-Up (1986)</td>\n",
       "      <td>Action|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>7831</td>\n",
       "      <td>Another Thin Man (1939)</td>\n",
       "      <td>Comedy|Crime|Drama|Mystery|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>48518</td>\n",
       "      <td>Texas Chainsaw Massacre: The Beginning, The (2...</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>60291</td>\n",
       "      <td>Gonzo: The Life and Work of Dr. Hunter S. Thom...</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>1167</td>\n",
       "      <td>Dear God (1996)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                              title  \\\n",
       "1981     2475                                  52 Pick-Up (1986)   \n",
       "5249     7831                            Another Thin Man (1939)   \n",
       "6540    48518  Texas Chainsaw Massacre: The Beginning, The (2...   \n",
       "6989    60291  Gonzo: The Life and Work of Dr. Hunter S. Thom...   \n",
       "927      1167                                    Dear God (1996)   \n",
       "\n",
       "                                  genres  \n",
       "1981             Action|Mystery|Thriller  \n",
       "5249  Comedy|Crime|Drama|Mystery|Romance  \n",
       "6540                     Horror|Thriller  \n",
       "6989                         Documentary  \n",
       "927                               Comedy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample five random movies\n",
    "movies.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31123.291836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40782.633604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2850.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>164979.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             movieId\n",
       "count    9125.000000\n",
       "mean    31123.291836\n",
       "std     40782.633604\n",
       "min         1.000000\n",
       "25%      2850.000000\n",
       "50%      6290.000000\n",
       "75%     56274.000000\n",
       "max    164979.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics for the movies data set\n",
    "movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11203</th>\n",
       "      <td>73</td>\n",
       "      <td>26603</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1469772963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92954</th>\n",
       "      <td>616</td>\n",
       "      <td>79</td>\n",
       "      <td>3.0</td>\n",
       "      <td>860573029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78102</th>\n",
       "      <td>544</td>\n",
       "      <td>4022</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1442496159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91024</th>\n",
       "      <td>605</td>\n",
       "      <td>1321</td>\n",
       "      <td>3.0</td>\n",
       "      <td>980174773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15864</th>\n",
       "      <td>102</td>\n",
       "      <td>2932</td>\n",
       "      <td>5.0</td>\n",
       "      <td>957894251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "11203      73    26603     3.5  1469772963\n",
       "92954     616       79     3.0   860573029\n",
       "78102     544     4022     4.0  1442496159\n",
       "91024     605     1321     3.0   980174773\n",
       "15864     102     2932     5.0   957894251"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample five random ratings\n",
    "ratings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100004.000000</td>\n",
       "      <td>100004.000000</td>\n",
       "      <td>100004.000000</td>\n",
       "      <td>1.000040e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>347.011310</td>\n",
       "      <td>12548.664363</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>1.129639e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>195.163838</td>\n",
       "      <td>26369.198969</td>\n",
       "      <td>1.058064</td>\n",
       "      <td>1.916858e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.896520e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>182.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.658478e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>367.000000</td>\n",
       "      <td>2406.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.110422e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>520.000000</td>\n",
       "      <td>5418.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.296192e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>671.000000</td>\n",
       "      <td>163949.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.476641e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100004.000000  100004.000000  100004.000000  1.000040e+05\n",
       "mean      347.011310   12548.664363       3.543608  1.129639e+09\n",
       "std       195.163838   26369.198969       1.058064  1.916858e+08\n",
       "min         1.000000       1.000000       0.500000  7.896520e+08\n",
       "25%       182.000000    1028.000000       3.000000  9.658478e+08\n",
       "50%       367.000000    2406.500000       4.000000  1.110422e+09\n",
       "75%       520.000000    5418.000000       4.000000  1.296192e+09\n",
       "max       671.000000  163949.000000       5.000000  1.476641e+09"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics for the ratings data set\n",
    "ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9066"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique movies in the ratings data file\n",
    "len(pd.unique(ratings['movieId'].ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "As the previous cells indicated, the `ratings` and `movies` DataFrames have a common column, `movieId`, which we can use to join these DataFrames together. This allows us to better understand these data, since we can see the name of the movie being rated (as opposed to just a `movieId`. In the next few code cells, we join these two DataFrames, display a few rows from the new DataFrame, and use Pandas functionality to display the most popular (by number of reviews) movies, as well as the movies that have the highest average ratings. \n",
    "\n",
    "The last task employs several useful tools. First, we perform a `groupby` operation where we employ two operations: mean value and size of sample. This creates a new data structure that has a special column that contains the number of reviews (from the size function) and a special column that contains the average rating (from the `mean` function). We can display the most popular (in terms of average rating), by first restricting the data structure to only those movies that have been rated twenty or more times, and display the first few rows of the sorted data in descending order.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge two dataframes, the common column is selected aotumatically\n",
    "mv_lens = pd.merge(movies, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851866703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>938629179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1331380058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>997938310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>855190091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title                                       genres  \\\n",
       "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "1        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "2        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "3        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "4        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "\n",
       "   userId  rating   timestamp  \n",
       "0       7     3.0   851866703  \n",
       "1       9     4.0   938629179  \n",
       "2      13     5.0  1331380058  \n",
       "3      15     2.0   997938310  \n",
       "4      19     3.0   855190091  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first five lines of combined DataFrame\n",
    "mv_lens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Forrest Gump (1994)                          341\n",
       "Pulp Fiction (1994)                          324\n",
       "Shawshank Redemption, The (1994)             311\n",
       "Silence of the Lambs, The (1991)             304\n",
       "Star Wars: Episode IV - A New Hope (1977)    291\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the most commonly rated movies\n",
    "mv_lens.title.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Godfather, The (1972)</th>\n",
       "      <td>200.0</td>\n",
       "      <td>4.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shawshank Redemption, The (1994)</th>\n",
       "      <td>311.0</td>\n",
       "      <td>4.487138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>On the Waterfront (1954)</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All About Eve (1950)</th>\n",
       "      <td>38.0</td>\n",
       "      <td>4.434211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ran (1985)</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.423077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 rating          \n",
       "                                   size      mean\n",
       "title                                            \n",
       "Godfather, The (1972)             200.0  4.487500\n",
       "Shawshank Redemption, The (1994)  311.0  4.487138\n",
       "On the Waterfront (1954)           29.0  4.448276\n",
       "All About Eve (1950)               38.0  4.434211\n",
       "Ran (1985)                         26.0  4.423077"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a new Data structure that holds the movie, number of ratings, and the average rating.\n",
    "mv_stats = mv_lens.groupby('title').agg({'rating': [np.size, np.mean]})\n",
    "\n",
    "# Number of ratings to consider top movie\n",
    "rating_count = 20\n",
    "\n",
    "# Display most popular movies.\n",
    "top_movies = mv_stats['rating']['size'] >= rating_count\n",
    "mv_stats[top_movies].sort_values(by=('rating', 'mean'), ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "## User Based Collaborative Filtering\n",
    "\n",
    "We can now turn our attention to developing a collaborative filter to make recommendations. The basic idea we will employ is to find the user who is most _similar_ to the current user, and use the ratings from this one similar user to make recommendations. To do this, we need two things. First, we need a matrix that contains the movie ratings, indexed by the user id and the movie id. This allows us to find movies to recommend, given a particular user. Second, we need a definition of similarity, which implies a [distance measurement][scdm] (more similar things should be close, while different things should be far apart). There are a number of different distance measures that are employed, including [Euclidean distance][wed], [Manhattan distance][wmd], and [cosine similarity][wcs].\n",
    "\n",
    "In this Notebook, we will employ cosine similarity. However, we will not use the implementation in the scipy library since it is not exactly appropriate for what we need. The cosine similarity treats two sets of data as vectors. For example, we can make a vector for each user where each element in the array corresponds to a rating for a specific movie. obviously, for a rating system with many movies, these vectors are extremely long (in our case, there are $10, 325$ elements). The cosine similarity is calculated by multiplying these two vectors and dividing by their length. Thus, this measurement will be scaled to lie between $-1$ and $1$. If the value is one, the vectors are identical. If the value is minus one, the vectors are exactly opposite of each other. And if the value is zero, the vectors are perpendicular to each other. As a result, the cosine similarity is measuring the angle between the two vectors.\n",
    "\n",
    "To get started, we first construct a pivot table to reference the movie ratings from each user.\n",
    "\n",
    "-----\n",
    "[scdm]: http://docs.scipy.org/doc/scipy/reference/spatial.distance.html\n",
    "\n",
    "[wed]: https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "[wmd]: https://en.wikipedia.org/wiki/Taxicab_geometry\n",
    "[wcs]: https://en.wikipedia.org/wiki/Cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a pivot table containing ratings indexed by user id and movie id\n",
    "tmp_df = ratings.pivot(index='userId', columns='movieId', values='rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "The values in this pivot table hold the actual ratings. For simplicity, we can restrict our analysis to only _favorable_ ratings, which, since the movies are rated on a five-star system, we take to mean ratings greater than three. We convert the pivot table to hold one for favorable ratings and zero for unfavorable ratings and convert the result to a NumPy matrix. The shape of the matrix indicates we have $671$ unique users, who have each rated one or more of $9,066$ movies.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671, 9066)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "the_data = tmp_df.applymap(lambda x: 1 if x > 3 else 0).as_matrix()\n",
    "print(the_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "This matrix is quite large, if we were processing the full movie data set, it would be prohibitively expensive. Fortunately, there is a simple fact that we can leverage. In general, we will not want to include items that haven't been rated enough times. This concept is sometimes called the _support_. Without sufficient ratings, we can't make accurate predictions as the power of this algorithm comes from leveraging data collected from multiple people who (ideally at least) have rated many things.\n",
    "\n",
    "As a result, we will generate a new pivot table, by first grouping the movies together, sorting into descending order, and selecting only those movies that have been reviewed by multiple people (in this case we will select only movies that have been reviewed at least `rating_count` or more times. By default in this notebook, this variable is twenty, which means only those movies rated at least twenty times will be included in our analysis. Next, we create our pivot table as before, and change the ratings into either zero (if rated three or less) or one (if rated four or five). The shape of the matrix is now considerably smaller, with only $136$ unique users and $928$ unique movies.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group ratings by movie ID\n",
    "mvrs = ratings.groupby('movieId').size().sort_values(ascending=False)\n",
    "\n",
    "# Select top rated movies\n",
    "tmp_ratings = ratings.ix[mvrs[mvrs > rating_count].index].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table\n",
    "tmp_df = tmp_ratings.pivot(index='userId', columns='movieId', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 928)\n"
     ]
    }
   ],
   "source": [
    "#  Map number of ratings to 0 or 1\n",
    "the_data = tmp_df.applymap(lambda x: 1 if x > 3 else 0).as_matrix()\n",
    "print(the_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Cosine Similarity\n",
    "\n",
    "We now create our function to compute the cosine similarity between our two vectors. We use simple NumPy commands, and subsequently demonstrate it being used on sample vectors.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the Cosine Similarity function\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    return(np.dot(u, v)/np.sqrt((np.dot(u, u) * np.dot(v, v))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity(a, b) = 0.000\n",
      "cosine similarity(a, c) = 0.333\n",
      "cosine similarity(b, c) = 0.816\n",
      "cosine similarity(a, a) = 1.000\n"
     ]
    }
   ],
   "source": [
    "# Test Cosine Similarity\n",
    "a = np.array([1, 1, 1, 0, 0])\n",
    "b = np.array([0, 0, 0, 1, 1])\n",
    "c = np.array([0, 1, 0, 1, 1])\n",
    "\n",
    "print('cosine similarity(a, b) = {0:4.3f}'.format(cosine_similarity(a, b)))\n",
    "print('cosine similarity(a, c) = {0:4.3f}'.format(cosine_similarity(a, c)))\n",
    "print('cosine similarity(b, c) = {0:4.3f}'.format(cosine_similarity(b, c)))\n",
    "\n",
    "print('cosine similarity(a, a) = {0:4.3f}'.format(cosine_similarity(a, a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Single User Recommendation\n",
    "\n",
    "We now develop the algorithm to make a recommendation for a single user. To do this, we first create a _fake_ user, by selecting several movies as favorable (effectively we simply make a new user vector). Given this new vector, we compute the cosine similarity between this new user and all users in our reduced data user-movie matrix. We identify the user who is most similar by selecting the row in the user-movie matrix with the highest cosine similarity, extract the movies favorably rated by this particular user, remove any that have already been rated by our _fake_ user, and display the results.\n",
    "\n",
    "To simplify the identification of the correct movie title, we add a new column to the DataFrame that holds the joined rating and movie data to map between movieId in our user-movie matrix and the movieID used in the original data.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The user-movie matrix\n",
    "x = the_data\n",
    "\n",
    "# Make a fake user (with movie ratings that will gaurantee a match)\n",
    "y = np.zeros(the_data.shape[1], dtype=np.int32)\n",
    "y[6] = 1 ; y[10] = 1; y[15] = 1; y[64] = 1; y[136] = 1\n",
    "y[180] = 1; y[230] = 1; y[339] = 1; y[622] = 1; y[703] = 1\n",
    "\n",
    "# Add a special index column to map the row in the x matrix to the userIds\n",
    "tmp_df.tmp_idx = np.array(range(x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\n",
      "Cosine Similarity(y, x[39]) = 0.183\n",
      "\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity, find maximum value\n",
    "sims = np.apply_along_axis(cosine_similarity, 1, x, y)\n",
    "mx = np.nanmax(sims)\n",
    "\n",
    "# Find the best matching user\n",
    "usr_idx = np.where(sims==mx)[0][0]\n",
    "\n",
    "# Print the first thirty reviews of test user and matched user.\n",
    "print(y[:30])\n",
    "print(x[usr_idx, :30])\n",
    "\n",
    "print('\\nCosine Similarity(y, x[{0:d}]) = {1:4.3f}' \\\n",
    "      .format(usr_idx, cosine_similarity(y, x[usr_idx])), end='\\n\\n')\n",
    "\n",
    "# Now we subtract the vectors\n",
    "# (any negative value is a movie to recommend)\n",
    "mov_vec = y - x[usr_idx]\n",
    "\n",
    "# We want a mask aray, so we zero out any recommended movie.\n",
    "mov_vec[mov_vec >= 0] = 1\n",
    "mov_vec[mov_vec < 0] = 0\n",
    "\n",
    "print(mov_vec[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Movie Recommendations for User = 43.0\n"
     ]
    }
   ],
   "source": [
    "# Print out the number of movies we will recommend.\n",
    "print('\\n{0} Movie Recommendations for User = {1}' \\\n",
    "      .format(mov_vec[mov_vec == 0].shape[0], \n",
    "              tmp_df[tmp_df.tmp_idx == usr_idx].index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns (movieIds) for the current user\n",
    "mov_ids = tmp_df[tmp_df.tmp_idx == usr_idx].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make a masked array to find movies to recommend\n",
    "# values are the movie ids, mask is the movies the most\n",
    "# similar user liked.\n",
    "\n",
    "ma_mov_idx = ma.array(mov_ids, mask = mov_vec)\n",
    "mov_idx = ma_mov_idx[~ma_mov_idx.mask]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Braveheart (1995)\n",
      "Jurassic Park (1993)\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now make a DataFrame of the moves of interest and display\n",
    "\n",
    "mv_df = movies.ix[movies.movieId.isin(mov_idx)].dropna()\n",
    "\n",
    "print(60*'-')\n",
    "\n",
    "for movie in mv_df.title.values:\n",
    "    print(movie)\n",
    "\n",
    "print(60*'-', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "In the preceding cells, we used cosine similarity to find the user most similar to a test (or fake) user in order to make recommendations. Now that you have run the Notebook, go back and make the following changes to see how the results change.\n",
    "\n",
    "1. Make a new fake user, ensure that there are movies in common with more than one real user. What movies are now recommended? Do they make sense?\n",
    "2. Try changing the `ratings_count` variable higher and lower. How does this change the results of the recommendation? Note this affects both the construction of the user-movie DataFrame and the final matrix.\n",
    "3. The current algorithm uses the only favorable ratings, but that isn't necessary. Try mapping the ratings to the space $-1, 1$ and repeating the analysis. In this mapping, $-1$ corresponds to an unfavorable rating of one. How do the results change?\n",
    "\n",
    "Finally, the current algorithm finds the _best matching_ user and uses that user's ratings to make a recommendation. In reality, we would want to use $n$ best matching users to make a recommendation. Change the algorithm to capture the five most similar users and to display the aggregated results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----\n",
    "\n",
    "[[Back to TOC]](#Table-of-Contents)\n",
    "\n",
    "### Multiple User Recommendation\n",
    "\n",
    "The previous example provided recommendations for a single user. We can extend this example to make recommendations for multiple users. In this case, however, we still use the same basic algorithm. First, we divide our data into two samples: training and testing. We then iterate through our testing set to find the best matching user to compute recommendations for the current testing sample user. Finally, the recommendations are displayed for each user in the test sample.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Define multiple user data set\n",
    "x, y = the_data, range(the_data.shape[0])\n",
    "\n",
    "# Create train:test splits\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(x, y, test_size = 0.1, random_state=42)\n",
    "\n",
    "# Add an index into the user-movie DataFrame for the movies that are in the\n",
    "# user-movie matrix.\n",
    "tmp_df.tmp_idx = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Movie Recommendations for User = 56.0\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "\n",
      "0 Movie Recommendations for User = 13.0\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "\n",
      "0 Movie Recommendations for User = 20.0\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "\n",
      "21 Movie Recommendations for User = 48.0\n",
      "------------------------------------------------------------\n",
      "Seven (a.k.a. Se7en) (1995)\n",
      "Usual Suspects, The (1995)\n",
      "Braveheart (1995)\n",
      "Star Wars: Episode IV - A New Hope (1977)\n",
      "Pulp Fiction (1994)\n",
      "Forrest Gump (1994)\n",
      "Fugitive, The (1993)\n",
      "Robin Hood: Men in Tights (1993)\n",
      "Schindler's List (1993)\n",
      "So I Married an Axe Murderer (1993)\n",
      "Amadeus (1984)\n",
      "Stand by Me (1986)\n",
      "Jaws (1975)\n",
      "Saving Private Ryan (1998)\n",
      "Office Space (1999)\n",
      "Ferris Bueller's Day Off (1986)\n",
      "Fight Club (1999)\n",
      "Crouching Tiger, Hidden Dragon (Wo hu cang long) (2000)\n",
      "Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Strange Brew (1983)\n",
      "Catch Me If You Can (2002)\n",
      "------------------------------------------------------------\n",
      "\n",
      "52 Movie Recommendations for User = 27.0\n",
      "------------------------------------------------------------\n",
      "Leaving Las Vegas (1995)\n",
      "Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "Hackers (1995)\n",
      "Johnny Mnemonic (1995)\n",
      "Smoke (1995)\n",
      "Star Wars: Episode IV - A New Hope (1977)\n",
      "Pulp Fiction (1994)\n",
      "Shawshank Redemption, The (1994)\n",
      "Bullets Over Broadway (1994)\n",
      "Carlito's Way (1993)\n",
      "Manhattan Murder Mystery (1993)\n",
      "True Romance (1993)\n",
      "Silence of the Lambs, The (1991)\n",
      "Citizen Kane (1941)\n",
      "Basic Instinct (1992)\n",
      "Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "Goodfellas (1990)\n",
      "Killer, The (Die xue shuang xiong) (1989)\n",
      "Blues Brothers, The (1980)\n",
      "Shining, The (1980)\n",
      "Hamlet (1996)\n",
      "L.A. Confidential (1997)\n",
      "U Turn (1997)\n",
      "Big Lebowski, The (1998)\n",
      "Rosemary's Baby (1968)\n",
      "Dead Ringers (1988)\n",
      "Matrix, The (1999)\n",
      "New Rose Hotel (1998)\n",
      "Crimes and Misdemeanors (1989)\n",
      "Mariachi, El (1992)\n",
      "Hamlet (2000)\n",
      "Mulholland Drive (2001)\n",
      "Vanilla Sky (2001)\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
      "Monster's Ball (2001)\n",
      "Professional, The (Le professionnel) (1981)\n",
      "Equilibrium (2002)\n",
      "Intact (Intacto) (2001)\n",
      "Tenebre (1982)\n",
      "Tenant, The (Locataire, Le) (1976)\n",
      "Matchstick Men (2003)\n",
      "Videodrome (1983)\n",
      "Hannah and Her Sisters (1986)\n",
      "Macbeth (a.k.a. Tragedy of Macbeth, The) (1971)\n",
      "Shoot the Piano Player (Tirez sur le pianiste) (1960)\n",
      "D.O.A. (1950)\n",
      "Samouraï, Le (Godson, The) (1967)\n",
      "Jetée, La (1962)\n",
      "Angels with Dirty Faces (1938)\n",
      "The Machinist (2004)\n",
      "Audition (Ôdishon) (1999)\n",
      "Return, The (Vozvrashcheniye) (2003)\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each user in test set.\n",
    "for idx, user in enumerate(x_test):\n",
    "    \n",
    "    # Compute similarity, find maximum value\n",
    "    sims = np.apply_along_axis(cosine_similarity, 1, x_train, user)\n",
    "    mx = np.nanmax(sims)\n",
    "    \n",
    "    # If maximum value is a real value    \n",
    "    if mx > 0:\n",
    "        \n",
    "        # Find the index in the similarity matrix with maximum value\n",
    "        train_idx = np.where(sims==mx)[0][0]\n",
    "        \n",
    "        # Now we subtract the vectors \n",
    "        # (any negative value is a movie to recommend)\n",
    "        mov_vec = user - x_train[train_idx]\n",
    "        \n",
    "        # We make a mask aray, so we zero out any recommended movie.\n",
    "        mov_vec[mov_vec >= 0] = 1\n",
    "        mov_vec[mov_vec < 0] = 0\n",
    "        \n",
    "        # We use the fact that y_train has the indices into the original\n",
    "        # temporary data frame\n",
    "\n",
    "        user_idx = tmp_df[tmp_df.tmp_idx == y_train[train_idx]]\n",
    "\n",
    "        # State how many movies are being recommend for this user id\n",
    "        print('{0} Movie Recommendations for User = {1}' \\\n",
    "              .format(mov_vec[mov_vec == 0].shape[0], \\\n",
    "                      tmp_df[tmp_df.tmp_idx == y_test[idx]].index[0]))\n",
    "        \n",
    "        print(60*'-')\n",
    "        # Now make a masked array to find movies to recommend\n",
    "        # values are the movie ids, mask is the movies the most\n",
    "        # similar user liked.\n",
    "        ma_mov_idx = ma.array(user_idx.columns, mask = mov_vec)\n",
    "        mov_idx = ma_mov_idx[~ma_mov_idx.mask]\n",
    "        \n",
    "        # Now make a DataFrame of the moves of interest and display\n",
    "        mv_df = movies.ix[movies.movieId.isin(mov_idx)].dropna()\n",
    "        for movie in mv_df.title.values:\n",
    "            print(movie)\n",
    "            \n",
    "        print(60*'-', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "<font color='red' size = '5'> Student Exercise </font>\n",
    "\n",
    "In the preceding cell, we computed the cosine similarity between test and training data to make recommendations.  Now that you have run the notebook, go back and make the following changes to see how the results change.\n",
    "\n",
    "1. Right now, the algorithm uses **only** the best matching user. Change the algorithm to use the five best matching users to develop a more complete set of movie ratings.\n",
    "\n",
    "2. In some cases, the best matching user does not exist. Change the `rating_count` variable so that all movies are included. How does this change the performance and results of the algorithm?\n",
    "\n",
    "This example has been a user-based collaborative filtering. If we transpose our matrix, however, we have a movie-user matrix, which can be used to make item-based collaborative filtering recommendations. In this case, you will find users who have rated the current movie and use their other ratings to find movies to recommend. Implement this new algorithm by following this description and the previous code.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ancillary Information\n",
    "\n",
    "The following links are to additional documentation that you might find helpful in learning this material. Reading these web-accessible documents is completely optional.\n",
    "\n",
    "1. A nice introduction to [recommendation systems][1] from IBM\n",
    "2. Wikipedia article on [Recommender system][wr]\n",
    "3. Wikipedia article on [Apriori algorithm][wa]\n",
    "4. Wikipedia article on [Cosine similarity][wc]\n",
    "5. An article on [recommender systems][2] from the Encyclopedia of Machine Learning\n",
    "6. Article on [association rules][3]\n",
    "-----\n",
    "\n",
    "[1]: https://www.ibm.com/developerworks/library/os-recommender1/index.html\n",
    "[wr]: https://en.wikipedia.org/wiki/Recommender_system\n",
    "[wa]: https://en.wikipedia.org/wiki/Apriori_algorithm\n",
    "[wc]: https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "[2]: http://www.prem-melville.com/publications/recommender-systems-eml2010.pdf\n",
    "[3]: http://aimotion.blogspot.com/2013/01/machine-learning-and-data-mining.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**&copy; 2017: Robert J. Brunner at the University of Illinois.**\n",
    "\n",
    "This notebook is released under the [Creative Commons license CC BY-NC-SA 4.0][ll]. Any reproduction, adaptation, distribution, dissemination or making available of this notebook for commercial use is not allowed unless authorized in writing by the copyright holder.\n",
    "\n",
    "[ll]: https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
