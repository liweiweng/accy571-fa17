{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 Assignment\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_ â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c87d48dfd2196899728365eb974d9797",
     "grade": false,
     "grade_id": "cell-5d125056cb79ad2a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import helper\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance\n",
    "from nltk.corpus import reuters\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following problems we will use the NLTK Reuters corpus which contains 10,788 documents which have been classified into 90 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "61d1517f4e0bc971b201d85e87b0939c",
     "grade": false,
     "grade_id": "cell-4b60e77c8ce3ade1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Let's take a look at the categories\n",
    "print(reuters.categories())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Find the number of times a particular token occurs\n",
    "\n",
    "Write a function called $\\texttt{token_counter}$ which takes in an nltk corpora and outputs the number of times a particular token occurs in the corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6f5852a2ed12e48fe200f814efc5e0b5",
     "grade": false,
     "grade_id": "cell-d4609143baf90e44",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def token_counter(token,corpora):\n",
    "    '''\n",
    "    Inputs\n",
    "    -------\n",
    "    \n",
    "    token: the token to search for\n",
    "    corpora: a list of documents\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    \n",
    "    count: the number of times the token occurs in the corpora\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "765e6ace33f42af3a6000406198908ee",
     "grade": true,
     "grade_id": "cell-6fc4830ca34cb389",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "num_to = token_counter('to',reuters)\n",
    "assert_equal(num_to,34035)\n",
    "num_ship = token_counter('ship',reuters)\n",
    "assert_equal(num_ship,116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a149ba41d5fe7275ca522a6083923b23",
     "grade": false,
     "grade_id": "cell-a1029d5f1c82309e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word', lowercase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Use CountVectorizer to retrieve the corpus vocabulary\n",
    "\n",
    "Write a function called $\\texttt{most_common_words}$ which uses CountVectorizer to return the vocabulary of the corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e605e82d4cb7207bd88c38fd0c162620",
     "grade": false,
     "grade_id": "cell-320c4d5d381fae3f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def most_common_words(corpora):\n",
    "    '''\n",
    "    Inputs\n",
    "    -------\n",
    "\n",
    "    corpora: a list of documents\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    \n",
    "    vocabulary: a Python dictionary containing each word and its count\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fc09cabec2d3f2c8dbc81f8ad99b3db8",
     "grade": true,
     "grade_id": "cell-d6a90ab9d83a28cf",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "vocabulary = most_common_words(reuters)\n",
    "assert_is_instance(vocabulary,dict)\n",
    "assert_equal(vocabulary['asian'],3384)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Reading and Preprocessing Data\n",
    "Read in the [badges dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/badges/badges.info) (it is stored in the same directory as 'badges.data') using which ever method you like (pandas, numpy, built-in python modules). *HINT: I recommend using pandas to read in this **fixed width** dataset.* \n",
    "\n",
    "The first column are the labels we want to predict (the + or - sign); the second column are the names. If you do this step correctly the data will be identical to the first 5 rows below:\n",
    "```\n",
    "[['+', 'Naoki Abe'],\n",
    " ['-', 'Myriam Abramson'],\n",
    " ['+', 'David W. Aha'],\n",
    " ['+', 'Kamal M. Ali'],\n",
    " ['-', 'Eric Allender']]\n",
    "```\n",
    "\n",
    "Depending on how you read in the data. Format your data so that it is in an acceptable format for [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function in in sci-kit learn.\n",
    "\n",
    "Next Split the data set the random_state parameter to be 0, and assign the approriate parameter to set aside 80% of your dataset for training data.\n",
    "\n",
    "Now encode your labels using [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder). \n",
    "\n",
    "Next create a [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) model using sci-kit learn's implementation using the default values.\n",
    "\n",
    "For your training features learn the vocabulary and idf and return the term-document matrix. For your testing set **only** transform documents to a document term matrix.\n",
    "\n",
    "Assign your encoded labels to train_y and test_y for the training and testing labels respectively.\n",
    "Assign your document-term matrices to the training and testing document-term matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d27914d4feb9fc8adb344c1a342c559e",
     "grade": false,
     "grade_id": "cell-22b77393ce3fb980",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f0e1ad13acf7a9aaa562ef3f5450c99d",
     "grade": true,
     "grade_id": "cell-2b0f7b5ae4588ecb",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(train_y.tolist(), [0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
    "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
    "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
    "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
    "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
    "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "       1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 1, 0])\n",
    "\n",
    "assert_equal(test_y.tolist(), [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Fit a Naive Bayes Multinomial Model to the Badges dataset\n",
    "Use sci-kit learn's implementation of a [naive bayes classifer for multinomial model](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) to fit a model to the Badges dataset. Lastly get predictions of the testing labels and name your predictions *_pred*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "08311cdc37c2db2335a0374c7ed1f5a3",
     "grade": false,
     "grade_id": "cell-48de75d9feeddc8d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "738a50ad38920dd26b182db125e066f0",
     "grade": false,
     "grade_id": "cell-b09a021688c4c4ac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(_pred, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cf63cf767695ad560ccaa3d5c4932713",
     "grade": true,
     "grade_id": "cell-c075ab26e7d7a622",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(_pred.tolist(), [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5: Using N-Grams to classify badges \n",
    "Use sci-kit learn's  [Count Vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). Learn the names and transform the training term-document matrix.\n",
    "For the testing names transform into the testing term-document matrix.\n",
    "\n",
    "Next create another Multinomial Naive Bayes model.\n",
    "Fit the model on the  training term-document matrix and training labels.\n",
    "Next make predictions on the testing labels with the testing term-document matrix. store this value as *p*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a6edcf7f97e6480e47a6ffd6dc0026c9",
     "grade": false,
     "grade_id": "cell-1015cdc20b7f9990",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b3ad51b4048d2a97273a1aa8dfb2fb51",
     "grade": false,
     "grade_id": "cell-18880fea825e4308",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(test_y, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d81520361b74039e48fa7e0a4058c2f1",
     "grade": true,
     "grade_id": "cell-4589c856766ce624",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(p.tolist(), [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we will use the NLTK Reuters corpus which contains 10,788 documents which have been classified into 90 topics. The documents have file ids (held in the $\\texttt{fileids()}$ method) which denotes if they are training or testing documents. An example is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c1b5ea4bd3c45d34c69fc581fec11838",
     "grade": false,
     "grade_id": "cell-600d14ee45bd7d8e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Let's look at the file id for the first document\n",
    "reuters.fileids()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6: Write a function that splits the reuters data into testing and training sets\n",
    "\n",
    "Write a function called $\\texttt{splitter}$ which takes in a corpora, and returns a list of file ids for the training documents, and a list of file ids for the testing documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "53c1d612f0c6038d3ab31fbe67c620ae",
     "grade": false,
     "grade_id": "cell-1223e8a718a4bbde",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def splitter(corpora):\n",
    "    \"\"\"\n",
    "\n",
    "    Inputs\n",
    "    ----------\n",
    "\n",
    "    corpora: an nltk corpora\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    trainig_ids: a list of training document file ids\n",
    "    testing_ids: a list of testing document file ids\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return training_ids, testing_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "316590bdb908936c8c769b6d110f504c",
     "grade": true,
     "grade_id": "cell-1a23052376286497",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_ids, testing_ids = splitter(reuters)\n",
    "assert_equal(len(training_ids),7769)\n",
    "assert_equal(len(testing_ids),3019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will use the below function, along with the training and testing ids that we found to get the full testing and training datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b62bd0ef1bba3b978ece327c46553744",
     "grade": false,
     "grade_id": "cell-ec94a27b2e25fd19",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_categories_from_fileids(corpus, fileids):\n",
    "    \"\"\"\n",
    "    Finds categories for each element of 'fileids'.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus: An NLTK corpus.\n",
    "    fileids: A list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of strings.\n",
    "    \"\"\"\n",
    "    \n",
    "    result = [sorted(corpus.categories(fileids=f))[0] for f in fileids]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "216e2974373b17cd738197dccfbc59a0",
     "grade": false,
     "grade_id": "cell-060b818d70d46b0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train = [reuters.raw(fileids=fileid) for fileid in training_ids][:1000]\n",
    "y_train = get_categories_from_fileids(reuters, training_ids)[:1000]\n",
    "\n",
    "\n",
    "X_test = [reuters.raw(fileids=fileid) for fileid in testing_ids]\n",
    "y_test = get_categories_from_fileids(reuters, testing_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7: Fit a naive bayes classifier using different n-grams\n",
    "\n",
    "Write a function called $\\texttt{naivebayes_categories}$ which takes in a training set of data, a lower n-gram range, and an upper n-gram range. Furthermore, use english stop words in the CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0bf646aa8f1a6a7376c7485b0e8a8e32",
     "grade": false,
     "grade_id": "cell-30b8f9c73b7265d9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def naivebayes_categories(X_train, y_train, lower, upper):\n",
    "    \"\"\"\n",
    "\n",
    "    Inputs\n",
    "    ----------\n",
    "    X_train: The training data\n",
    "    y_train: The training labels\n",
    "    lower: the lower n_gram range\n",
    "    upper: the upper n_gram range\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    clf: the fitted model\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "04be889d6dc26a616e602f282319cf6f",
     "grade": true,
     "grade_id": "cell-d36114816765a759",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "model = naivebayes_categories(X_train,y_train,1,2)\n",
    "predictions = model.predict(X_test)\n",
    "assert_is_instance(model,Pipeline)\n",
    "assert_equal(model.classes_[0],'acq')\n",
    "assert_equal(predictions[0],'trade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how accurate the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8c61fc6d9e8a1dba1ac81ecaf0c585b7",
     "grade": false,
     "grade_id": "cell-4f62b7031b128b60",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
