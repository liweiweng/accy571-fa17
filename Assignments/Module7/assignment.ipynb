{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 7 Assignment\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_ â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6d850fc04ab542f2138ab7d6b29873be",
     "grade": false,
     "grade_id": "cell-21cc344642c5bb59",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nose.tools import assert_equal, assert_is_instance,assert_true\n",
    "import email as em\n",
    "import tweepy as tw\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "from email import policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the below problems we're going to use a fake e-mail message whose text is shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"From: Hilldawg <no-reply@private_email_sever.private>\\nSubject: [SECRET] Guess what!\\nDate: September 29, 2016 at 5:54:37 PM CDT\\nTo: Bdog@whitehouse.gov\\n\\nHey big-O, it's ya girl Hillary C.\\n\\nI'm out here on the campaign trail, trying to get these kids to pokemon-go-to-the-polls and you'll never guess what just happened.\\n\\nI saw that old boy Bernie Sanders trying to lift at the gym and he is a total LOSER! He couldn't even bench 1 plate! No wonder he couldn't beat me in the primaries. \\n\\nAnyways, i'll catch ya after the election. Keep the oval office warm for me.\\n\\nXOXO gossip girl.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Read in an e-mail and return the text\n",
    "\n",
    "Write a function called $\\texttt{email_reader}$ that takes in an e-mail file and returns $\\textbf{only}$ the text of the e-mail, not any of the other information such as the to, from, date, or subject. Note that our e-mail message is not multipart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8a610e2b54ba3012266f6e10c73e0d4c",
     "grade": false,
     "grade_id": "cell-deedf4add3a7f4f3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def email_reader(file):\n",
    "    '''\n",
    "    Inputs\n",
    "    -------\n",
    "    file: an e-mail file to be read in\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    \n",
    "    text: the text of the e-mail, without the from, date, to, or subject information\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a2ba0d11c1e19defbd84b7369a7d253a",
     "grade": false,
     "grade_id": "cell-22b56ce9171b81d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "email = '''Hey big-O, it's ya girl Hillary C.\\n\\nI'm out here on the campaign trail, trying to get these kids\n",
    "to pokemon-go-to-the-polls and you'll never guess what just happened.\\n\\nI saw that old boy Bernie Sanders\n",
    "trying to lift at the gym and he is a total LOSER! He couldn't even bench 1 plate!\n",
    "No wonder he couldn't beat me in the primaries. \\n\\nAnyways, i'll catch ya after the election.\n",
    "Keep the oval office warm for me.\\n\\nXOXO gossip girl.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "25d0b39e3d81697036735486e8c1b099",
     "grade": true,
     "grade_id": "cell-2c1cd5a732bd3761",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(email_reader(\"email.eml\"),str)\n",
    "assert_equal(430,len(email_reader(\"email.eml\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Read in an e-mail and return the header information\n",
    "\n",
    "Write a function called $\\texttt{header_info}$ which takes in a an email file and returns $\\textbf{only}$ the header information. It should return the \"to\" field, the \"from\" field, and the \"subject\" field, in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e84e3f511ddcec7e3dc2e61e83d542bb",
     "grade": false,
     "grade_id": "cell-f50c1e1964f1a0b6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def header_info(filename):\n",
    "    '''\n",
    "    Inputs\n",
    "    ----------\n",
    "    file: an e-mail file to be read in\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    to: A string. The \"To\" field.\n",
    "    From: A string. The \"From\" field.\n",
    "    subject: A string. The \"subject\" field.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return to, From, subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ebbf4bb68d97e575e41e58ffcb205bbc",
     "grade": true,
     "grade_id": "cell-4f5e71eca922f3b2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "info = header_info('email.eml')\n",
    "assert_equal(info[0],'Bdog@whitehouse.gov')\n",
    "assert_equal(info[1],'Hilldawg <no-reply@private_email_sever.private>')\n",
    "assert_equal(info[2],'[SECRET] Guess what!')\n",
    "assert_is_instance(header_info('email.eml'),tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Connecting to Twitter\n",
    "For the problem below write a function called *twitter_connect* by doing the following:\n",
    "- Create a Twitter Application\n",
    "- Store your creditionals file (Consumer Key/Secret; Access Tokne/ Token Secret) in the same directory and name it twitter.cred (the assert statement will assume this file is in the directory). \n",
    "- Your function should be called twitter_connect\n",
    "- Pass  your consumer token & secret to OAuthHandler in Tweepy.\n",
    "- Next set the access token to be your access token and token secret in your creditionals file.\n",
    "- Finally return the OAuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6dbf94adaad97aedb9da5335248f0182",
     "grade": false,
     "grade_id": "cell-75dafe06270d89c9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def twitter_connect(cred_file):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2a815d17acfb64456a4a697bf386fd4f",
     "grade": true,
     "grade_id": "cell-58368bd0f0a04bdb",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_true(os.path.exists('./twitter.cred'), msg='Create your cred file and store it the same dir as ./twitter.cred')\n",
    "auth = twitter_connect('./twitter.cred')\n",
    "assert_equal(type(auth), tw.OAuthHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f03b11bd13fe9550b707af865dfb7922",
     "grade": false,
     "grade_id": "cell-49189afa2dde1c0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "api = tw.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Grabbing Tweets\n",
    "Grab all the Tweets from this account: KC74292876 and store the content of each tweet in a list called public_tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "667c480b6236d825c338e479717d513d",
     "grade": false,
     "grade_id": "cell-3afe16252216c6df",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aec3bfba7f732d609a80441b2b6a8a6e",
     "grade": true,
     "grade_id": "cell-78f3f27ee43beb86",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(public_tweets, \n",
    "['RT @chancetherapper: I just got the package in the mail, thanks so much. You are a great friend @StephenAtHome', 'RT @nowthisnews: In a powerful speech, Joe Biden explained why Doug Jones should be Alabamaâ€™s fist Democratic senator in 25 years https://tâ€¦', 'RT @chancetherapper: Kid Cudi just brought out Kanye in Chicago', 'RT @redturn2: Honored to have had the opportunity to step in the box against the Hall of Famer Roy Halladay. Sick to my stomach to hear theâ€¦', 'RT @astros: We join the rest of the baseball world in mourning todayâ€™s tragic passing of Roy Halladay. We send our heartfelt condolences toâ€¦', 'RT @jonmorosi: Roy Halladay made his @MLB debut in 1998. He still has the most complete games since then: 67.', 'RT @realDonaldTrump: Unemployment is down to 4.1%, lowest in 17 years. 1.5 million new jobs created since I took office. Highest stock Markâ€¦', 'RT @realDonaldTrump: Heading into the 12 days with great negotiating strength because of our tremendous economy. https://t.co/4HnXkR3EhW', 'RT @realDonaldTrump: May God be w/ the people of Sutherland Springs, Texas. The FBI &amp; law enforcement are on the scene. I am monitoring theâ€¦', 'RT @realDonaldTrump: #USAðŸ‡ºðŸ‡¸ #JapanðŸ‡¯ðŸ‡µ https://t.co/EvxFqAVnFS', 'RT @realDonaldTrump: The state of Virginia economy, under Democrat rule, has been terrible. If you vote Ed Gillespie tomorrow, it will comeâ€¦', 'RT @realDonaldTrump: ....and has been horrible on Virginia economy. Vote @EdWGillespie today!', \"RT @realDonaldTrump: Thank you to all Americans who participated in Nat'l Rx Drug Take Back Day. A record amount of drugs collected &amp; dispoâ€¦\", \"RT @BarackObama: John McCain is an American hero &amp; one of the bravest fighters I've ever known. Cancer doesn't know what it's up against. Gâ€¦\", 'RT @BarackObama: Thinking about our neighbors in Mexico and all our Mexican-American friends tonight. Cuidense mucho y un fuerte abrazo parâ€¦', 'RT @BarackObama: Iâ€™ll let you and @ladygaga handle the singing, and weâ€™ll handle the donations. Thereâ€™s still time to give: https://t.co/o5â€¦', 'RT @BarackObama: We grieve with all the families in Sutherland Springs harmed by this act of hatred, and weâ€™ll stand with the survivors asâ€¦', \"RT @BarackObama: Michelle and I are thinking of the victims of today's attack in NYC and everyone who keeps us safe. New Yorkers are as touâ€¦\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "727416d9685c4dd05081cdc27b1de58c",
     "grade": false,
     "grade_id": "cell-777615676c2e476a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the first 5 tweets\n",
    "for tweet in public_tweets[0:5]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Module 3, we downloaded  html files from a world bank webpage and found specific values in a table. We have downloaded the WV1.html file and it is in a directory called world_bank which is located in your current directory. You can view the webpage here: http://wdi.worldbank.org/table/WV.1 (*if you cannot view the link download the WV.1.html file in the current directory and view it in your browser locally*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5: Count the number of tables\n",
    "\n",
    "Write a function called $\\texttt{table_count}$ which parses a website and then returns the number of html tables on that website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "39b9078472753533a4ad472c2698c310",
     "grade": false,
     "grade_id": "cell-a43c9b367b9d1f3d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def table_count(file_path):\n",
    "    '''\n",
    "    Inputs\n",
    "    ------\n",
    "    file_path: The file path of the saved website\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    num_tables: the number of tables in the website\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return num_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3e785150b1909efaf1e58c39265ad543",
     "grade": true,
     "grade_id": "cell-fa1e68acc0e9c3cd",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "file_path = './world_bank/WV.1.html'\n",
    "assert_equal(table_count(file_path),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a68aedf67250d9168bba456ead9e4d67",
     "grade": false,
     "grade_id": "cell-eeb25c09cdbff6df",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#See how many tables there are\n",
    "print(table_count(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6: Grabbing all data from the World Bank Table\n",
    "\n",
    "Complete the function below called get_world_bank_data by completing the following instructions:\n",
    "\n",
    " Use beautifulSoup to parse the html and grab all values from the **table** *(hint)*. After you grab all the values make a Pandas Dataframe with the column names:\n",
    "- Country\n",
    "- Population\n",
    "- Surface area\n",
    "Population density\n",
    "- Gross national income, Atlas method\n",
    "- Gross national income per capita, Atlas method\n",
    "- Purchasing power parity gross national income (billions)\n",
    "- Purchasing power parity gross national income (per capita)\n",
    "- Gross domestic product (%growth)\n",
    "- Gross domestic product (per capita % growth)\n",
    "\n",
    "Here's how the first 5 lines for W.V.1 should look:\n",
    "![./world_bank/sampleOutput.png](./world_bank/sampleOutput.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b7c5d917a91b5f68c0f1d6ed10a1bd66",
     "grade": false,
     "grade_id": "cell-e2cecf1a47c37be5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_world_bank_data(file_path):\n",
    "    '''\n",
    "    file_path: path to a file\n",
    "    : returns dataframe\n",
    "    '''\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "48e76e05053a6796340f3c96d0d1b117",
     "grade": false,
     "grade_id": "cell-e7dd1701cfbd8681",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df1= get_world_bank_data('./world_bank/WV.1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bb1f5370f5c74226b944593438a2758b",
     "grade": false,
     "grade_id": "cell-5425ececfd12d395",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cfa15420c5b1ee7209c8b4fd4f85ec04",
     "grade": true,
     "grade_id": "cell-429f29806a70f3a7",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(df1.columns.values.tolist(), ['Country', 'Gross domestic product (%growth)', 'Gross domestic product (per capita % growth)', 'Gross national income per capita, Atlas method', 'Gross national income, Atlas method', 'Population', 'Population density', 'Purchasing power parity gross national income (billions)', 'Purchasing power parity gross national income (per capita)', 'Surface area'], msg='Your header does not match the solutions')\n",
    "assert_equal(df1['Country'].values.tolist(), ['Afghanistan', 'Albania', 'Algeria', 'American Samoa', 'Andorra', 'Angola', 'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas, The', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bermuda', 'Bhutan', 'Bolivia', 'Bosnia and Herzegovina', 'Botswana', 'Brazil', 'Brunei Darussalam', 'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Cabo Verde', 'Cayman Islands', 'Central African Republic', 'Chad', 'Channel Islands', 'Chile', 'China', 'Hong Kong SAR, China', 'Macao SAR, China', 'Colombia', 'Comoros', 'Congo, Dem. Rep.', 'Congo, Rep.', 'Costa Rica', \"Cote d'Ivoire\", 'Croatia', 'Cuba', 'Curacao', 'Cyprus', 'Czech Republic', 'Denmark', 'Djibouti', 'Dominica', 'Dominican Republic', 'Ecuador', 'Egypt, Arab Rep.', 'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia', 'Ethiopia', 'Faroe Islands', 'Fiji', 'Finland', 'France', 'French Polynesia', 'Gabon', 'Gambia, The', 'Georgia', 'Germany', 'Ghana', 'Greece', 'Greenland', 'Grenada', 'Guam', 'Guatemala', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', 'Honduras', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran, Islamic Rep.', 'Iraq', 'Ireland', 'Isle of Man', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jordan', 'Kazakhstan', 'Kenya', 'Kiribati', 'Korea, Dem. Peopleâ€™s Rep.', 'Korea, Rep.', 'Kosovo', 'Kuwait', 'Kyrgyz Republic', 'Lao PDR', 'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macedonia, FYR', 'Madagascar', 'Malawi', 'Malaysia', 'Maldives', 'Mali', 'Malta', 'Marshall Islands', 'Mauritania', 'Mauritius', 'Mexico', 'Micronesia, Fed. Sts.', 'Moldova', 'Monaco', 'Mongolia', 'Montenegro', 'Morocco', 'Mozambique', 'Myanmar', 'Namibia', 'Nauru', 'Nepal', 'Netherlands', 'New Caledonia', 'New Zealand', 'Nicaragua', 'Niger', 'Nigeria', 'Northern Mariana Islands', 'Norway', 'Oman', 'Pakistan', 'Palau', 'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Romania', 'Russian Federation', 'Rwanda', 'Samoa', 'San Marino', 'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Serbia', 'Seychelles', 'Sierra Leone', 'Singapore', 'Sint Maarten (Dutch part)', 'Slovak Republic', 'Slovenia', 'Solomon Islands', 'Somalia', 'South Africa', 'South Sudan', 'Spain', 'Sri Lanka', 'St. Kitts and Nevis', 'St. Lucia', 'St. Martin (French part)', 'St. Vincent and the Grenadines', 'Sudan', 'Suriname', 'Swaziland', 'Sweden', 'Switzerland', 'Syrian Arab Republic', 'Tajikistan', 'Tanzania', 'Thailand', 'Timor-Leste', 'Togo', 'Tonga', 'Trinidad and Tobago', 'Tunisia', 'Turkey', 'Turkmenistan', 'Turks and Caicos Islands', 'Tuvalu', 'Uganda', 'Ukraine', 'United Arab Emirates', 'United Kingdom', 'United States', 'Uruguay', 'Uzbekistan', 'Vanuatu', 'Venezuela, RB', 'Vietnam', 'Virgin Islands (U.S.)', 'West Bank and Gaza', 'Yemen, Rep.', 'Zambia', 'Zimbabwe', 'World', 'East Asia & Pacific', 'Europe & Central Asia', 'Latin America & Caribbean', 'Middle East & North Africa', 'North America', 'South Asia', 'Sub-Saharan Africa', 'Low income', 'Lower middle income', 'Upper middle income', 'High income'], 'Your first column does not match the solutions')\n",
    "assert_equal(df1['Population'].values.tolist(), ['34.7', '2.9', '40.6', '0.1', '0.1', '28.8', '0.1', '43.8', '2.9', '0.1', '24.1', '8.7', '9.8', '0.4', '1.4', '163.0', '0.3', '9.5', '11.3', '0.4', '10.9', '0.1', '0.8', '10.9', '3.5', '2.3', '207.7', '0.4', '7.1', '18.6', '10.5', '15.8', '23.4', '36.3', '0.5', '0.1', '4.6', '14.5', '0.2', '17.9', '1,378.7', '7.3', '0.6', '48.7', '0.8', '78.7', '5.1', '4.9', '23.7', '4.2', '11.5', '0.2', '1.2', '10.6', '5.7', '0.9', '0.1', '10.6', '16.4', '95.7', '6.3', '1.2', '..', '1.3', '102.4', '0.0', '0.9', '5.5', '66.9', '0.3', '2.0', '2.0', '3.7', '82.7', '28.2', '10.7', '0.1', '0.1', '0.2', '16.6', '12.4', '1.8', '0.8', '10.8', '9.1', '9.8', '0.3', '1,324.2', '261.1', '80.3', '37.2', '4.8', '0.1', '8.5', '60.6', '2.9', '127.0', '9.5', '17.8', '48.5', '0.1', '25.4', '51.2', '1.8', '4.1', '6.1', '6.8', '2.0', '6.0', '2.2', '4.6', '6.3', '0.0', '2.9', '0.6', '2.1', '24.9', '18.1', '31.2', '0.4', '18.0', '0.4', '0.1', '4.3', '1.3', '127.5', '0.1', '3.6', '0.0', '3.0', '0.6', '35.3', '28.8', '52.9', '2.5', '0.0', '29.0', '17.0', '0.3', '4.7', '6.1', '20.7', '186.0', '0.1', '5.2', '4.4', '193.2', '0.0', '4.0', '8.1', '6.7', '31.8', '103.3', '37.9', '10.3', '3.4', '2.6', '19.7', '144.3', '11.9', '0.2', '0.0', '0.2', '32.3', '15.4', '7.1', '0.1', '7.4', '5.6', '0.0', '5.4', '2.1', '0.6', '14.3', '55.9', '12.2', '46.4', '21.2', '0.1', '0.2', '0.0', '0.1', '39.6', '0.6', '1.3', '9.9', '8.4', '18.4', '8.7', '55.6', '68.9', '1.3', '7.6', '0.1', '1.4', '11.4', '79.5', '5.7', '0.0', '0.0', '41.5', '45.0', '9.3', '65.6', '323.1', '3.4', '31.8', '0.3', '31.6', '92.7', '0.1', '4.6', '27.6', '16.6', '16.2', '7,442.1', '2,296.8', '912.0', '637.7', '436.7', '359.5', '1,766.4', '1,033.1', '659.3', '3,012.9', '2,579.9', '1,190.0'], msg= 'Last column does not match solutions')\n",
    "assert_equal(df1['Surface area'].values.tolist(), ['652.9', '28.8', '2,381.7', '0.2', '0.5', '1,246.7', '0.4', '2,780.4', '29.7', '0.2', '7,741.2', '83.9', '86.6', '13.9', '0.8', '147.6', '0.4', '207.6', '30.5', '23.0', '114.8', '0.1', '38.4', '1,098.6', '51.2', '581.7', '8,515.8', '5.8', '111.0', '274.2', '27.8', '181.0', '475.4', '9,984.7', '4.0', '0.3', '623.0', '1,284.0', '0.2', '756.1', '9,562.9', '1.1', '0.0', '1,141.7', '1.9', '2,344.9', '342.0', '51.1', '322.5', '56.6', '109.9', '0.4', '9.3', '78.9', '42.9', '23.2', '0.8', '48.7', '256.4', '1,001.5', '21.0', '28.1', '117.6', '45.2', '1,104.3', '1.4', '18.3', '338.4', '549.1', '4.0', '267.7', '11.3', '69.7', '357.4', '238.5', '132.0', '410.5', '0.3', '0.5', '108.9', '245.9', '36.1', '215.0', '27.8', '112.5', '93.0', '103.0', '3,287.3', '1,910.9', '1,745.2', '435.1', '70.3', '0.6', '22.1', '301.3', '11.0', '378.0', '89.3', '2,724.9', '580.4', '0.8', '120.5', '100.3', '10.9', '17.8', '199.9', '236.8', '64.5', '10.5', '30.4', '111.4', '1,759.5', '0.2', '65.3', '2.6', '25.7', '587.3', '118.5', '330.8', '0.3', '1,240.2', '0.3', '0.2', '1,030.7', '2.0', '1,964.4', '0.7', '33.9', '0.0', '1,564.1', '13.8', '446.6', '799.4', '676.6', '824.3', '0.0', '147.2', '41.5', '18.6', '267.7', '130.4', '1,267.0', '923.8', '0.5', '385.2', '309.5', '796.1', '0.5', '75.4', '462.8', '406.8', '1,285.2', '300.0', '312.7', '92.2', '8.9', '11.6', '238.4', '17,098.3', '26.3', '2.8', '0.1', '1.0', '2,149.7', '196.7', '88.4', '0.5', '72.3', '0.7', '0.0', '49.0', '20.3', '28.9', '637.7', '1,219.1', '644.3', '505.9', '65.6', '0.3', '0.6', '0.1', '0.4', '1,879.4', '163.8', '17.4', '447.4', '41.3', '185.2', '141.4', '947.3', '513.1', '14.9', '56.8', '0.8', '5.1', '163.6', '785.4', '488.1', '1.0', '0.0', '241.6', '603.6', '83.6', '243.6', '9,831.5', '176.2', '447.4', '12.2', '912.1', '331.0', '0.4', '6.0', '528.0', '752.6', '390.8', '134,325.1', '24,825.2', '28,461.1', '20,425.5', '11,370.6', '19,816.2', '5,135.3', '24,291.1', '14,471.5', '23,351.5', '59,651.5', '36,850.7'], msg='Last column does not match solutions')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
